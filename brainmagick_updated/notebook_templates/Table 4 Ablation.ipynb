{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "from concurrent.futures import ProcessPoolExecutor\n",
    "from pathlib import Path\n",
    "import pandas as pd\n",
    "from omegaconf import OmegaConf\n",
    "import os\n",
    "import torch\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt \n",
    "from matplotlib.gridspec import GridSpec\n",
    "from tqdm.notebook import tqdm\n",
    "import bm\n",
    "os.chdir(Path(bm.__file__).parent.parent)\n",
    "from bm import train\n",
    "\n",
    "%matplotlib inline\n",
    "%config InlineBackend.figure_format='retina'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/checkpoint/defossez/brainmagick/experiments\n",
      "['01cd28fc', 'ec29e81e', '2dd6ddbe', '55751f43', '8e9c33b1', '4438d221', 'fb2cced8', '480110a3', '9e8b929d', 'f33cf48b', 'b476448e', 'ceb23552', 'ca8c38f8', '85f40582', 'ff85bfd6', '81bd9784', '048edc79', '70a0e185', '092d508e', 'a5acd4a3', 'c3b555db', 'b978fc86', '1dd888f0', 'fc475d47', '41831434', 'fa2d2578', '08cf8898', '38449131', 'bb4f4ee9', '666e391f', 'e48c36ea', '6577f78f', '22fb342c', 'd605ce2f', '2aecc316', 'd890f8eb', '493023a0', '5d3de32c', '16d17b9c', '27332012', 'de507ded', '2325aad9', '64c1362f', 'f3cae34e', '49efae33', 'c32f25b6', 'b23c2cfa', '832d9622', '036741ea', '766c6d08', 'c4098073', 'e521c72b', 'ac5b3b57', '3cf51478', 'bea7f00a', 'bd7d06d2', '1bd6de99', '55c4a03c', '0896a4a8', '0d4f43b4', '86811260', 'd9cec30d', '5b38fa38', '4479100b', '73c5dce9', '9ed67c53', 'bd30ebf1', 'ea519a2a', '8d13203d', '2ae3913a', '22d2260a', '6324264b', 'd3399072', 'a5e3ebae', '5c633e70', '0e6262e9', '7f15adbc', 'bd231c7a', '437a096c', 'e5c6b552', '0f34bbaf', '1d014dcd', '957fe7a4', 'a781c6a7', '5f8b5d6a', '00e0bdcd', '8ababc44', '84f95be4', '6b9ba19e', '8a7419d6', '22ca6dba', '3a9ae364', '1481dbbb', '4e9d4727', 'ac741d87', 'cfe0aefd', '91c5c41b', '745a6231', 'd1d37637', 'e059e7e5', '57a34964', 'd43b1b05', '0f17594c', '5d7a51d4', '46c3d964', '9783831e', '9567ff2c', '78d5d473', 'd733b028', 'fbdd79aa', 'bd04f96e', 'd4cf1bbe', '5c64a266', '850b80f6', '87c1ffa6', '3d61e840', '15546f79', '626f961e', '76b0e85a', '203c64a9', 'c1150d28', 'ce18f336', '58a6fa89', '4c3a83bf', 'a4b730f1', '6019c47b', '0c80dd82', '5349feef', 'bba535c9', '71dd6af4', 'b8d46745', '586f1ad0', '9690b6df', '7794017b', 'cc151cb8', 'f5f480e9', '3b328157', '0e69aa5d', '5352fd2c', 'cfc3eb74', 'ad4ced9d', '83367e48', 'c0f2e4ba', '91776f65']\n"
     ]
    }
   ],
   "source": [
    "output_dir = train.main.dora.dir\n",
    "print(output_dir)\n",
    "eval_dir = output_dir / \"eval\" / \"signatures\"\n",
    "sigs_to_eval = [p.name for p in (output_dir / \"grids\" / \"ablation_final\").iterdir()]\n",
    "# sigs_to_eval = [p.name for p in (output_dir / \"grids\" / \"lr_batch_size\").iterdir()]\n",
    "# eval_dir = Path('/private/home/defossez/projs/brainmagick/outputs/eval/signatures_final')\n",
    "# sigs_to_eval = [p.name for p in eval_dir.iterdir()]\n",
    "print(sigs_to_eval)\n",
    "assert output_dir.exists()\n",
    "# assert grid_dir.exists()\n",
    "assert eval_dir.exists()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Common functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_data_from_sig(sig, level=\"segment\"):\n",
    "    \"\"\"\n",
    "    Load data from solver signature\n",
    "    - probs (torch tensor): probability on vocab [N, V]\n",
    "    - vocab (torch tensor): vocab of word hashes [V]\n",
    "    - words (torch tensor): the word hash for each sample [N]\n",
    "    - metadata (panda dataframe) of len [N] which contains for each sample:\n",
    "           'word_hashes', 'word_indices', 'seq_indices',\n",
    "           'word_strings', 'subject_id', 'recording_id'\n",
    "    \"\"\"\n",
    "    assert level in [\"word\", \"segment\"], \"level should be 'word' or 'segment'\"\n",
    "    probs = torch.load(eval_dir / sig / f\"probs_{level}.pth\") \n",
    "    vocab = torch.load(eval_dir / sig / f\"vocab_{level}.pth\") # vocab (hashes)\n",
    "    metadata = pd.read_csv(eval_dir / sig / \"metadata.csv\", index_col=0, low_memory=False) \n",
    "    \n",
    "    words = torch.tensor(metadata[f\"{level}_hashes\"].tolist()).long() # for each sample, the word (hashes)\n",
    "    assert probs.shape == (len(words), len(vocab)), (probs.shape, len(words), len(vocab))\n",
    "    assert len(words) == len(metadata)\n",
    "    metadata[\"idx\"] = range(len(words))\n",
    "    metadata[\"word_strings\"] = metadata[\"word_strings\"].str.lower()\n",
    "\n",
    "    return probs, vocab, words, metadata\n",
    "\n",
    "\n",
    "def get_accuracy_from_probs(probs, row_labels, col_labels, topk=10):\n",
    "    \"\"\"\n",
    "    probs: for each row, the probability distribution over a vocab\n",
    "    returns the topk accuracy that the topk best predicted labels\n",
    "    match the row_labels\n",
    "    Inputs:\n",
    "        probs: of shape [B, V] probability over vocab, each row sums to 1\n",
    "        row_labels: of shape [B] true word for each row\n",
    "        col_labels: [V] word that correspond to each column\n",
    "        topk: int\n",
    "    Returns: float scalar, topk accuracy\n",
    "    \"\"\"\n",
    "    assert len(row_labels) == len(probs)\n",
    "    assert len(col_labels) == probs.shape[1]\n",
    "\n",
    "    # Extract topk indices\n",
    "    idx = probs.topk(topk, dim=1).indices\n",
    "\n",
    "    # Get the corresponding topk labels\n",
    "    whs = col_labels[idx.view(-1)].reshape(idx.shape)\n",
    "\n",
    "    # 1 if the labels matches with the targets\n",
    "    correct = ((whs == row_labels[:, None]).any(1)).float()\n",
    "    assert len(correct) == len(row_labels)\n",
    "\n",
    "    # Average across samples\n",
    "    acc = correct.mean()\n",
    "\n",
    "    return acc.item()\n",
    "\n",
    "\n",
    "def eval_acc_one_sig(sig, topks=(1, 5, 10), level=\"word\", add_baselines=True):\n",
    "    \"\"\"\n",
    "    Return accuracy dataframe from one solver signature\n",
    "    level: whether to return `word` or `segment` level accuracy\n",
    "    \"\"\"\n",
    "    # Load data\n",
    "    probs, vocab, words, _ = load_data_from_sig(sig, level=level)\n",
    "#     if level == \"segment\":\n",
    "#         print(probs.shape)\n",
    "        \n",
    "    # Compute acc\n",
    "    acc_df = []\n",
    "    for topk in topks:\n",
    "        \n",
    "        # --- Acc ---\n",
    "        acc = get_accuracy_from_probs(probs, words, vocab, topk=topk)\n",
    "        \n",
    "        out = {\n",
    "            f\"acc\":acc,\n",
    "            \"topk\":topk,\n",
    "        }\n",
    "        \n",
    "        if add_baselines:\n",
    "        \n",
    "            # --- Baseline on vocab ---\n",
    "            # equivalent to : shuffle targets vocab (inf times)\n",
    "            # equivalent to : output uniform prob on vocab\n",
    "            # equivalent to : 1/vocab_len\n",
    "            rand_probs_vocab = torch.ones_like(probs) / len(vocab)\n",
    "            out[\"baseline_vocab\"] = get_accuracy_from_probs(rand_probs_vocab, words, vocab, topk=topk)\n",
    "\n",
    "            # --- Baseline on words ---\n",
    "            # equivalent to : shuffle word targets before aggregating on vocab (inf times)\n",
    "            # equivalent to : output uniform prob on samples\n",
    "            # equivalent to : each_word_freq\n",
    "            check_vocab, counts = torch.unique(words, return_counts=True)\n",
    "            import pdb\n",
    "#             assert (check_vocab == vocab).all()\n",
    "            rand_probs_words = torch.stack([counts/len(words)]*len(probs))\n",
    "            out[\"baseline\"] = get_accuracy_from_probs(rand_probs_words, words, vocab, topk=topk)\n",
    "\n",
    "            # Update\n",
    "            acc_df.append(out)\n",
    "    acc_df = pd.DataFrame(acc_df)\n",
    "    return acc_df\n",
    "\n",
    "def eval_acc(sigs, level=\"word\", add_baselines=True):\n",
    "    \"\"\"\n",
    "    Return accuracy dataframe for multiple sigs \n",
    "    level: whether to return word or segment level accuracy\n",
    "    \"\"\"\n",
    "    futures = []\n",
    "    acc = []\n",
    "    with ProcessPoolExecutor(20) as pool:\n",
    "        for sig in sigs:\n",
    "            future = pool.submit(eval_acc_one_sig, sig, level=level, add_baselines=add_baselines)\n",
    "            futures.append((sig, future))\n",
    "        for sig, future in tqdm(futures):\n",
    "            try:\n",
    "                acc_sig = future.result()\n",
    "            except Exception:\n",
    "                print(\"ERROR WITH\", sig)\n",
    "                raise\n",
    "                continue\n",
    "            acc_sig[\"sig\"] = sig\n",
    "            acc.append(acc_sig)\n",
    "    acc = pd.concat(acc)\n",
    "    return acc"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load meta dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "set()\n"
     ]
    }
   ],
   "source": [
    "# Select signatures\n",
    "valid_sigs = [sig for sig in sigs_to_eval if (eval_dir / sig / \"vocab_segment.pth\").is_file()]\n",
    "configs = [OmegaConf.load(eval_dir / sig / \"solver_config.yaml\") for sig in valid_sigs]\n",
    "for c, s in zip(configs, valid_sigs):\n",
    "    if not hasattr(c.dset, 'features'):\n",
    "        c.dset.features = c.dset.forcings\n",
    "        c.dset.features_params = c.dset.forcings_params\n",
    "        \n",
    "print(set(sigs_to_eval) - set(valid_sigs))\n",
    "run_df = pd.DataFrame({\n",
    "    \"sig\":valid_sigs,\n",
    "})\n",
    "run_df[\"dataset\"] = [\"-\".join(conf.dset.selections) for conf in configs]\n",
    "run_df[\"seed\"] = [conf.seed for conf in configs]\n",
    "run_df[\"forcings\"] = [\"-\".join(conf.dset.features) for conf in configs]\n",
    "run_df[\"loss\"] = [conf.optim.loss for conf in configs]\n",
    "run_df[\"is_random\"] = [conf.test.wer_random for conf in configs]\n",
    "run_df[\"max_scale\"] = [conf.norm.max_scale for conf in configs]\n",
    "run_df[\"n_mels\"] = [conf.dset.features_params.MelSpectrum.n_mels for conf in configs]\n",
    "run_df[\"deepmel\"] = [bool(conf.clip.arch) for conf in configs]\n",
    "run_df[\"ft\"] = [conf.optim.epochs == 1 and not conf.test.wer_random for conf in configs]\n",
    "run_df[\"random\"] = [conf.test.wer_random for conf in configs]\n",
    "\n",
    "run_df[\"batch_size\"] = [conf.optim.batch_size for conf in configs]\n",
    "run_df[\"lr\"] = [conf.optim.lr for conf in configs]\n",
    "run_df[\"autorej\"] = [conf.dset.autoreject for conf in configs]\n",
    "run_df[\"n_rec\"] = [conf.dset.n_recordings for conf in configs]\n",
    "# run_df[\"ft\"] = [conf.optim.lr == 0 for conf in configs]\n",
    "run_df[\"dropout\"] = [conf.simpleconv.merger_dropout > 0 for conf in configs]\n",
    "run_df[\"gelu\"] = [bool(conf.simpleconv.gelu) for conf in configs]\n",
    "run_df[\"skip\"] = [bool(conf.simpleconv.skip) for conf in configs]\n",
    "run_df[\"initial\"] = [bool(conf.simpleconv.initial_linear) for conf in configs]\n",
    "run_df[\"complex\"] = [bool(conf.simpleconv.complex_out) for conf in configs]\n",
    "run_df[\"subject_lay\"] = [bool(conf.simpleconv.subject_layers) for conf in configs]\n",
    "run_df[\"subject_emb\"] = [bool(conf.simpleconv.subject_dim) for conf in configs]\n",
    "run_df[\"attention\"] = [bool(conf.simpleconv.merger) for conf in configs]\n",
    "run_df[\"glu\"] = [bool(conf.simpleconv.glu) for conf in configs]\n",
    "run_df[\"depth\"] = [conf.simpleconv.depth for conf in configs]\n",
    "run_df[\"offset_meg\"] = [conf.task.offset_meg_ms for conf in configs]\n",
    "run_df = run_df[run_df.loss == \"clip\"]\n",
    "# run_df = run_df[run_df.dataset == \"gwilliams2022\"]\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_name(row):\n",
    "    if not row.dropout:\n",
    "        return r\"\\wo spatial attention dropout\"\n",
    "    if not row.gelu:\n",
    "        return r\"\\wo GELU, \\w ReLU\"\n",
    "    if not row.skip:\n",
    "        return r\"\\wo skip connections\"\n",
    "    if not row.initial:\n",
    "        return r\"\\wo initial 1x1 conv.\"\n",
    "    if not row.complex:\n",
    "        return r\"\\wo final convs\"\n",
    "    if not row.attention:\n",
    "        return r\"\\wo spatial attention\"\n",
    "    if not row.glu:\n",
    "        return r\"\\wo non-residual GLU conv.\"\n",
    "    if not row.subject_lay:\n",
    "        if row.subject_emb:\n",
    "            return r\"\\w subj. embedding*\"\n",
    "        else:\n",
    "            return r\"\\wo subject-specific layer\"\n",
    "    if row.depth == 5:\n",
    "        return r\"less deep\"\n",
    "    elif row.max_scale != 20:\n",
    "        if row.max_scale == 100:\n",
    "            return \"\\w clamp=100\"\n",
    "        else:\n",
    "            return \"\\wo clamping brain signal\"\n",
    "    return \"Our model\"\n",
    "    \n",
    "        \n",
    "run_df['name'] = run_df.apply(get_name, axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Accuracy table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "30c32914fd52413f9ddcefafe688ad27",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/144 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 277 ms, sys: 230 ms, total: 507 ms\n",
      "Wall time: 26.6 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "acc_df = eval_acc(run_df[\"sig\"].values, level=\"segment\")\n",
    "# acc_df = pd.merge(acc_df, on=[\"sig\", \"topk\"], how=\"outer\")\n",
    "def dset_order(name):\n",
    "    return name.map({\n",
    "       'audio_mous': 0, \n",
    "       'gwilliams2022': 1,\n",
    "       'broderick2019': 2,\n",
    "       'brennan2019': 3,\n",
    "    })\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                                 mean       std        str_acc\n",
      "dataset       name                                                            \n",
      "audio_mous    Our model                      0.673448  0.003624   67.3 PM 0.36\n",
      "              \\w clamp=100                   0.669298  0.007908   66.9 PM 0.79\n",
      "              \\w subj. embedding*            0.645722  0.003076   64.6 PM 0.31\n",
      "              \\wo GELU, \\w ReLU              0.656240  0.005631   65.6 PM 0.56\n",
      "              \\wo clamping brain signal      0.015385  0.003648    1.5 PM 0.36\n",
      "              \\wo final convs                0.672309  0.003212   67.2 PM 0.32\n",
      "              \\wo initial 1x1 conv.          0.626807  0.007912   62.7 PM 0.79\n",
      "              \\wo non-residual GLU conv.     0.667211  0.002295   66.7 PM 0.23\n",
      "              \\wo skip connections           0.652577  0.002846   65.3 PM 0.28\n",
      "              \\wo spatial attention          0.656174  0.004009    65.6 PM 0.4\n",
      "              \\wo spatial attention dropout  0.673134  0.001250   67.3 PM 0.12\n",
      "              \\wo subject-specific layer     0.423901  0.000613   42.4 PM 0.06\n",
      "brennan2019   Our model                      0.257462  0.029298   25.7 PM 2.93\n",
      "              \\w clamp=100                   0.271083  0.026298   27.1 PM 2.63\n",
      "              \\w subj. embedding*            0.294014  0.005932   29.4 PM 0.59\n",
      "              \\wo GELU, \\w ReLU              0.245650  0.021164   24.6 PM 2.12\n",
      "              \\wo clamping brain signal      0.140782  0.010240   14.1 PM 1.02\n",
      "              \\wo final convs                0.190263  0.043950    19.0 PM 4.4\n",
      "              \\wo initial 1x1 conv.          0.220750  0.019186   22.1 PM 1.92\n",
      "              \\wo non-residual GLU conv.     0.060016  0.001689    6.0 PM 0.17\n",
      "              \\wo skip connections           0.242511  0.026736   24.3 PM 2.67\n",
      "              \\wo spatial attention          0.205746  0.021506   20.6 PM 2.15\n",
      "              \\wo spatial attention dropout  0.268210  0.006784   26.8 PM 0.68\n",
      "              \\wo subject-specific layer     0.201915  0.013414   20.2 PM 1.34\n",
      "broderick2019 Our model                      0.134205  0.003863   13.4 PM 0.39\n",
      "              \\w clamp=100                   0.132911  0.002379   13.3 PM 0.24\n",
      "              \\w subj. embedding*            0.146883  0.004490   14.7 PM 0.45\n",
      "              \\wo GELU, \\w ReLU              0.125302  0.002159   12.5 PM 0.22\n",
      "              \\wo clamping brain signal      0.009778  0.003870    1.0 PM 0.39\n",
      "              \\wo final convs                0.111615  0.008943   11.2 PM 0.89\n",
      "              \\wo initial 1x1 conv.          0.118616  0.005215   11.9 PM 0.52\n",
      "              \\wo non-residual GLU conv.     0.068681  0.051256    6.9 PM 5.13\n",
      "              \\wo skip connections           0.109532  0.013252   11.0 PM 1.33\n",
      "              \\wo spatial attention          0.119005  0.004164   11.9 PM 0.42\n",
      "              \\wo spatial attention dropout  0.123276  0.011427   12.3 PM 1.14\n",
      "              \\wo subject-specific layer     0.068966  0.012509    6.9 PM 1.25\n",
      "gwilliams2022 Our model                      0.666881  0.001456   66.7 PM 0.15\n",
      "              \\w clamp=100                   0.665484  0.003598   66.5 PM 0.36\n",
      "              \\w subj. embedding*            0.667241  0.002490   66.7 PM 0.25\n",
      "              \\wo GELU, \\w ReLU              0.649303  0.012910   64.9 PM 1.29\n",
      "              \\wo clamping brain signal      0.223392  0.231713  22.3 PM 23.17\n",
      "              \\wo final convs                0.650576  0.009186   65.1 PM 0.92\n",
      "              \\wo initial 1x1 conv.          0.640000  0.006169   64.0 PM 0.62\n",
      "              \\wo non-residual GLU conv.     0.662559  0.001700   66.3 PM 0.17\n",
      "              \\wo skip connections           0.624054  0.002954    62.4 PM 0.3\n",
      "              \\wo spatial attention          0.618588  0.003485   61.9 PM 0.35\n",
      "              \\wo spatial attention dropout  0.651534  0.000852   65.2 PM 0.09\n",
      "              \\wo subject-specific layer     0.442916  0.012376   44.3 PM 1.24\n"
     ]
    }
   ],
   "source": [
    "keys = ['dataset', 'name']\n",
    "acc_table = pd.merge(acc_df, run_df, on=\"sig\", how=\"left\")\n",
    "acc_table = acc_table.sort_values([\"dataset\"], key=dset_order);\n",
    "acc_table = acc_table.query(\"topk==10\").sort_values(keys).groupby(keys)[\"acc\"].agg([\"mean\", \"std\"])\n",
    "key = \"acc\"\n",
    "acc_table[\"str_acc\"] = (100 * acc_table[\"mean\"]).round(1).astype(str) + r\" PM \" + (100 * acc_table[\"std\"]).round(2).astype(str)\n",
    "print(acc_table)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead tr th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe thead tr:last-of-type th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th colspan=\"7\" halign=\"left\">str_acc</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dataset</th>\n",
       "      <th>audio_mous</th>\n",
       "      <th>gwilliams2022</th>\n",
       "      <th>broderick2019</th>\n",
       "      <th>brennan2019</th>\n",
       "      <th>mean_dataset</th>\n",
       "      <th>delta</th>\n",
       "      <th>p_value</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>name</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>\\w subj. embedding*</th>\n",
       "      <td>64.6 PM 0.31</td>\n",
       "      <td>66.7 PM 0.25</td>\n",
       "      <td>14.7 PM 0.45</td>\n",
       "      <td>29.4 PM 0.59</td>\n",
       "      <td>43.8</td>\n",
       "      <td>0.5</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>\\w clamp=100</th>\n",
       "      <td>66.9 PM 0.79</td>\n",
       "      <td>66.5 PM 0.36</td>\n",
       "      <td>13.3 PM 0.24</td>\n",
       "      <td>27.1 PM 2.63</td>\n",
       "      <td>43.4</td>\n",
       "      <td>0.1</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Our model</th>\n",
       "      <td>67.3 PM 0.36</td>\n",
       "      <td>66.7 PM 0.15</td>\n",
       "      <td>13.4 PM 0.39</td>\n",
       "      <td>25.7 PM 2.93</td>\n",
       "      <td>43.3</td>\n",
       "      <td>0.0</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>\\wo spatial attention dropout</th>\n",
       "      <td>67.3 PM 0.12</td>\n",
       "      <td>65.2 PM 0.09</td>\n",
       "      <td>12.3 PM 1.14</td>\n",
       "      <td>26.8 PM 0.68</td>\n",
       "      <td>42.9</td>\n",
       "      <td>-0.4</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>\\wo GELU, \\w ReLU</th>\n",
       "      <td>65.6 PM 0.56</td>\n",
       "      <td>64.9 PM 1.29</td>\n",
       "      <td>12.5 PM 0.22</td>\n",
       "      <td>24.6 PM 2.12</td>\n",
       "      <td>41.9</td>\n",
       "      <td>-1.4</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>\\wo skip connections</th>\n",
       "      <td>65.3 PM 0.28</td>\n",
       "      <td>62.4 PM 0.3</td>\n",
       "      <td>11.0 PM 1.33</td>\n",
       "      <td>24.3 PM 2.67</td>\n",
       "      <td>40.8</td>\n",
       "      <td>-2.5</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>\\wo final convs</th>\n",
       "      <td>67.2 PM 0.32</td>\n",
       "      <td>65.1 PM 0.92</td>\n",
       "      <td>11.2 PM 0.89</td>\n",
       "      <td>19.0 PM 4.4</td>\n",
       "      <td>40.6</td>\n",
       "      <td>-2.7</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>\\wo initial 1x1 conv.</th>\n",
       "      <td>62.7 PM 0.79</td>\n",
       "      <td>64.0 PM 0.62</td>\n",
       "      <td>11.9 PM 0.52</td>\n",
       "      <td>22.1 PM 1.92</td>\n",
       "      <td>40.2</td>\n",
       "      <td>-3.1</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>\\wo spatial attention</th>\n",
       "      <td>65.6 PM 0.4</td>\n",
       "      <td>61.9 PM 0.35</td>\n",
       "      <td>11.9 PM 0.42</td>\n",
       "      <td>20.6 PM 2.15</td>\n",
       "      <td>40.0</td>\n",
       "      <td>-3.3</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>\\wo non-residual GLU conv.</th>\n",
       "      <td>66.7 PM 0.23</td>\n",
       "      <td>66.3 PM 0.17</td>\n",
       "      <td>6.9 PM 5.13</td>\n",
       "      <td>6.0 PM 0.17</td>\n",
       "      <td>36.5</td>\n",
       "      <td>-6.8</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>\\wo subject-specific layer</th>\n",
       "      <td>42.4 PM 0.06</td>\n",
       "      <td>44.3 PM 1.24</td>\n",
       "      <td>6.9 PM 1.25</td>\n",
       "      <td>20.2 PM 1.34</td>\n",
       "      <td>28.4</td>\n",
       "      <td>-14.9</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>\\wo clamping brain signal</th>\n",
       "      <td>1.5 PM 0.36</td>\n",
       "      <td>22.3 PM 23.17</td>\n",
       "      <td>1.0 PM 0.39</td>\n",
       "      <td>14.1 PM 1.02</td>\n",
       "      <td>9.7</td>\n",
       "      <td>-33.6</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                    str_acc                               \\\n",
       "dataset                          audio_mous  gwilliams2022 broderick2019   \n",
       "name                                                                       \n",
       "\\w subj. embedding*            64.6 PM 0.31   66.7 PM 0.25  14.7 PM 0.45   \n",
       "\\w clamp=100                   66.9 PM 0.79   66.5 PM 0.36  13.3 PM 0.24   \n",
       "Our model                      67.3 PM 0.36   66.7 PM 0.15  13.4 PM 0.39   \n",
       "\\wo spatial attention dropout  67.3 PM 0.12   65.2 PM 0.09  12.3 PM 1.14   \n",
       "\\wo GELU, \\w ReLU              65.6 PM 0.56   64.9 PM 1.29  12.5 PM 0.22   \n",
       "\\wo skip connections           65.3 PM 0.28    62.4 PM 0.3  11.0 PM 1.33   \n",
       "\\wo final convs                67.2 PM 0.32   65.1 PM 0.92  11.2 PM 0.89   \n",
       "\\wo initial 1x1 conv.          62.7 PM 0.79   64.0 PM 0.62  11.9 PM 0.52   \n",
       "\\wo spatial attention           65.6 PM 0.4   61.9 PM 0.35  11.9 PM 0.42   \n",
       "\\wo non-residual GLU conv.     66.7 PM 0.23   66.3 PM 0.17   6.9 PM 5.13   \n",
       "\\wo subject-specific layer     42.4 PM 0.06   44.3 PM 1.24   6.9 PM 1.25   \n",
       "\\wo clamping brain signal       1.5 PM 0.36  22.3 PM 23.17   1.0 PM 0.39   \n",
       "\n",
       "                                                                        \n",
       "dataset                         brennan2019 mean_dataset delta p_value  \n",
       "name                                                                    \n",
       "\\w subj. embedding*            29.4 PM 0.59         43.8   0.5          \n",
       "\\w clamp=100                   27.1 PM 2.63         43.4   0.1          \n",
       "Our model                      25.7 PM 2.93         43.3   0.0          \n",
       "\\wo spatial attention dropout  26.8 PM 0.68         42.9  -0.4          \n",
       "\\wo GELU, \\w ReLU              24.6 PM 2.12         41.9  -1.4          \n",
       "\\wo skip connections           24.3 PM 2.67         40.8  -2.5          \n",
       "\\wo final convs                 19.0 PM 4.4         40.6  -2.7          \n",
       "\\wo initial 1x1 conv.          22.1 PM 1.92         40.2  -3.1          \n",
       "\\wo spatial attention          20.6 PM 2.15         40.0  -3.3          \n",
       "\\wo non-residual GLU conv.      6.0 PM 0.17         36.5  -6.8          \n",
       "\\wo subject-specific layer     20.2 PM 1.34         28.4 -14.9          \n",
       "\\wo clamping brain signal      14.1 PM 1.02          9.7 -33.6          "
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def convert(x):\n",
    "    if isinstance(x, float):\n",
    "        print(x)\n",
    "    return float(x.split(\" \")[0])\n",
    "    \n",
    "toplot = acc_table.reset_index()\n",
    "index = list(keys)\n",
    "index.remove('dataset')\n",
    "toplot =  pd.pivot_table(toplot, values=[\"str_acc\"], columns=\"dataset\", index=index, aggfunc=\"first\")\n",
    "\n",
    "toplot[('str_acc', \"mean_dataset\")] = toplot.applymap(convert).mean(axis=1).round(1)\n",
    "toplot= toplot.sort_values([('str_acc', 'mean_dataset')], ascending=False)\n",
    "dsets = ['audio_mous', 'gwilliams2022', 'broderick2019', 'brennan2019']\n",
    "BASE_ACC = 43.3\n",
    "toplot[('str_acc', 'delta')] = toplot[('str_acc', \"mean_dataset\")] - BASE_ACC\n",
    "toplot[('str_acc', 'p_value')] = ''  # done in another notebook.\n",
    "extra = ['delta', 'p_value']\n",
    "\n",
    "toplot = toplot[[('str_acc', dset) \n",
    "                 for dset in dsets + ['mean_dataset'] +  extra]]\n",
    "toplot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\\begin{tabular}{lllllrrl}\n",
      "\\toprule\n",
      "{} & \\multicolumn{7}{l}{str\\_acc} \\\\\n",
      "dataset &    audio\\_mous &  gwilliams2022 & broderick2019 &   brennan2019 & mean\\_dataset & delta & p\\_value \\\\\n",
      "name                          &               &                &               &               &              &       &         \\\\\n",
      "\\midrule\n",
      "\\textbackslash w subj. embedding*           &  64.6 $\\pm$ 0.31 &   66.7 $\\pm$ 0.25 &  14.7 $\\pm$ 0.45 &  29.4 $\\pm$ 0.59 &         43.8 &   0.5 &         \\\\\n",
      "\\textbackslash w clamp=100                  &  66.9 $\\pm$ 0.79 &   66.5 $\\pm$ 0.36 &  13.3 $\\pm$ 0.24 &  27.1 $\\pm$ 2.63 &         43.4 &   0.1 &         \\\\\n",
      "Our model                     &  67.3 $\\pm$ 0.36 &   66.7 $\\pm$ 0.15 &  13.4 $\\pm$ 0.39 &  25.7 $\\pm$ 2.93 &         43.3 &   0.0 &         \\\\\n",
      "\\textbackslash wo spatial attention dropout &  67.3 $\\pm$ 0.12 &   65.2 $\\pm$ 0.09 &  12.3 $\\pm$ 1.14 &  26.8 $\\pm$ 0.68 &         42.9 &  -0.4 &         \\\\\n",
      "\\textbackslash wo GELU, \\textbackslash w ReLU             &  65.6 $\\pm$ 0.56 &   64.9 $\\pm$ 1.29 &  12.5 $\\pm$ 0.22 &  24.6 $\\pm$ 2.12 &         41.9 &  -1.4 &         \\\\\n",
      "\\textbackslash wo skip connections          &  65.3 $\\pm$ 0.28 &    62.4 $\\pm$ 0.3 &  11.0 $\\pm$ 1.33 &  24.3 $\\pm$ 2.67 &         40.8 &  -2.5 &         \\\\\n",
      "\\textbackslash wo final convs               &  67.2 $\\pm$ 0.32 &   65.1 $\\pm$ 0.92 &  11.2 $\\pm$ 0.89 &   19.0 $\\pm$ 4.4 &         40.6 &  -2.7 &         \\\\\n",
      "\\textbackslash wo initial 1x1 conv.         &  62.7 $\\pm$ 0.79 &   64.0 $\\pm$ 0.62 &  11.9 $\\pm$ 0.52 &  22.1 $\\pm$ 1.92 &         40.2 &  -3.1 &         \\\\\n",
      "\\textbackslash wo spatial attention         &   65.6 $\\pm$ 0.4 &   61.9 $\\pm$ 0.35 &  11.9 $\\pm$ 0.42 &  20.6 $\\pm$ 2.15 &         40.0 &  -3.3 &         \\\\\n",
      "\\textbackslash wo non-residual GLU conv.    &  66.7 $\\pm$ 0.23 &   66.3 $\\pm$ 0.17 &   6.9 $\\pm$ 5.13 &   6.0 $\\pm$ 0.17 &         36.5 &  -6.8 &         \\\\\n",
      "\\textbackslash wo subject-specific layer    &  42.4 $\\pm$ 0.06 &   44.3 $\\pm$ 1.24 &   6.9 $\\pm$ 1.25 &  20.2 $\\pm$ 1.34 &         28.4 & -14.9 &         \\\\\n",
      "\\textbackslash wo clamping brain signal     &   1.5 $\\pm$ 0.36 &  22.3 $\\pm$ 23.17 &   1.0 $\\pm$ 0.39 &  14.1 $\\pm$ 1.02 &          9.7 & -33.6 &         \\\\\n",
      "\\bottomrule\n",
      "\\end{tabular}\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-54-0411c7397620>:1: FutureWarning: In future versions `DataFrame.to_latex` is expected to utilise the base implementation of `Styler.to_latex` for formatting and rendering. The arguments signature may therefore change. It is recommended instead to use `DataFrame.style.to_latex` which also contains additional functionality.\n",
      "  print(toplot.to_latex(index=True).replace('PM', r'$\\pm$'))\n"
     ]
    }
   ],
   "source": [
    "print(toplot.to_latex(index=True).replace('PM', r'$\\pm$'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
